<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Steven&#39;s Blog</title>
    <description>A UChicago student&#39;s journey through machine learning and computer science.</description>
    <link>localhost:4000/</link>
    <atom:link href="localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 02 Mar 2016 11:15:54 -0600</pubDate>
    <lastBuildDate>Wed, 02 Mar 2016 11:15:54 -0600</lastBuildDate>
    <generator>Jekyll v2.2.0</generator>
    
      <item>
        <title>Adventures in Torch</title>
        <description>&lt;p&gt;For starters some of the basics about Torch.  Torch is a machine learning (more appropriately a neural network) library written in Lua. Lua’s syntax is somewhat similar to python (without the forced tabs), while it only contains one abstract container type that of a table. Lua tables are hashmaps and can be thought of to function in a similar way to javascripts prototypes.  For more on Lua one can check out this link &lt;a href=&quot;https://learnxinyminutes.com/docs/lua/&quot;&gt;Learn_Lua&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some examples of what you can quickly do in Torch:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;nb&quot;&gt;require&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;nn&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SpatialConvolution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A bit more about lua/torch.  All variables all global unless specified with local. The “:” operator passes in the variable as the first argument to the function. So model:add() will pass model as the first argument to add followed by the the next parameter which could be the nn.sigmoid function for example.  It’s similar to python in that the first parameter passed in when creating an objects is the “self” parameter.&lt;/p&gt;

&lt;p&gt;So this “simple” model will run a convolution that takes in an image (not necessarily an image but makes it easier to visualize) of  inputdimension 3 (think RGB), outputs dimension 1,  filter size is 3 x 3, step size is 1 in both horizontal and vetical and lastly is the zero padding of 1 on all sides of the image.  Those are all the specified parameters for the convolution.&lt;/p&gt;

&lt;p&gt;The next layer will take as input the convolution run it through a relu followed by dropout, then a linear layer before finally squashing all of the results into a sigmoid function.  For the linear layer I assumed the size of the image is 256*256 and the output that we want is 20 classes (think PASCAL VOC).&lt;/p&gt;

&lt;p&gt;Actually using the model is quite nice and easy once it’s set up.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Where inputs is a table of the input images you want to pass through the model.&lt;/p&gt;

&lt;p&gt;One needs to specify a loss function (in torch they are called criterion). Then pass in the output of the model and the associated ground truth labels.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df_doutput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally one can run backpropagation through the model given the associated derivatives.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_do&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The torch docs on github are quite good for most modules in my opinion.  It only becomes a little bit confusing once you ever need to use nn.Concat vs nn.ConcatTable vs nn.Parallel as the descriptions of what they actually do could be improved in my opinion.&lt;/p&gt;

&lt;p&gt;Torch itself is quite beautiful and in my opinion the main thing holding it back is Lua.  Many times the error will not actually tell you where the program crashed and I’m looking for a debugger that could maybe alleviate this situation.  The other thing to nitpick is that of one based indexing.  It messes up the beauty of using the modulo function when one needs to wrap around values and then index into a table by always needing to add one.&lt;/p&gt;

&lt;p&gt;In a followup post I’m going to work on creating a new layer in Torch.&lt;/p&gt;

</description>
        <pubDate>Tue, 01 Mar 2016 06:00:00 -0600</pubDate>
        <link>localhost:4000/torch/update/2016/03/01/Adventures-in-Torch/</link>
        <guid isPermaLink="true">localhost:4000/torch/update/2016/03/01/Adventures-in-Torch/</guid>
        
        
        <category>torch</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Image Processing</title>
        <description>&lt;p&gt;I took a course in Medical Image Processing and coded up some of the assignments in Javascript. All relevant code is provided on the links below.&lt;/p&gt;

&lt;p&gt;Here is an example of rotating an image using linear interpolation and via nearest neighbor.  In the same link is an example of using the Sobel Operator to enhance edges.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/examples/ImageProcessing/ex1/&quot;&gt;example1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here I show examples of edge tracing via 4 and 8 connectivity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/examples/ImageProcessing/ex2/&quot;&gt;example2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This shows examples of erode, dilate, and find the area of binary image. Erosion can be described as all the points in set A that any shift of set B is contained within A. Here’s a description from wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Erosion_(morphology)&quot;&gt;erosion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/examples/ImageProcessing/ex3/&quot;&gt;example3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This last example shows an example of calulating the Hough Transform to find circles and calculating the Haar wavelet.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/examples/ImageProcessing/ex4/&quot;&gt;example4&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 25 Dec 2015 16:18:57 -0600</pubDate>
        <link>localhost:4000/image_processing/update/2015/12/25/image-processing/</link>
        <guid isPermaLink="true">localhost:4000/image_processing/update/2015/12/25/image-processing/</guid>
        
        
        <category>image_processing</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Welcome to my Blog!</title>
        <description>&lt;p&gt;Welcome to my blog.  It will highlight my work and random learnings I do each month.&lt;/p&gt;
</description>
        <pubDate>Sun, 20 Dec 2015 16:18:57 -0600</pubDate>
        <link>localhost:4000/welcome/update/2015/12/20/welcome-to-jekyll/</link>
        <guid isPermaLink="true">localhost:4000/welcome/update/2015/12/20/welcome-to-jekyll/</guid>
        
        
        <category>welcome</category>
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
